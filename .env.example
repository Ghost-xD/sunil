# OpenAI API Configuration
OPENAI_API_KEY=your-openai-api-key-here

# Optional: Specify OpenAI model (defaults to gpt-4-turbo-preview)
# Available models:
#   - gpt-4.1 (GPT-4.1, fastest and most capable - recommended)
#   - gpt-4-turbo-preview (GPT-4 Turbo)
#   - gpt-4 (GPT-4)
#   - gpt-3.5-turbo (faster, less accurate)
OPENAI_MODEL=gpt-4.1

# Cache Configuration (saves tokens during development)
# Enable/disable caching of HTML and LLM responses
ENABLE_CACHE=true

# Cache TTL (time-to-live) in hours
CACHE_TTL_HOURS=24

